#!/bin/bash
# Cloud Runìš© ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸: Ollama + Qwen + FastAPI

set -e

# UTF-8 í™˜ê²½ ë° Ollama ë¡œê·¸ ë ˆë²¨ ì„¤ì •
export PYTHONIOENCODING=utf-8
export OLLAMA_DEBUG=0

echo "ğŸš€ Starting Ollama server..."
ollama serve 2>&1 | grep -v "print_info\|llama_\|ggml_\|rope_\|vocab\|token" &
OLLAMA_PID=$!

# Ollama ì„œë²„ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
echo "â³ Waiting for Ollama to be ready..."
for i in {1..60}; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama is ready!"
        break
    fi
    if [ $i -eq 60 ]; then
        echo "âŒ Ollama failed to start"
        exit 1
    fi
    sleep 1
done

# ëª¨ë¸ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
# kanana-counseling = finetuned ëª¨ë¸ (ë¡œì»¬ GGUF íŒŒì¼ ì‚¬ìš©)
# kanana = kakaocorp/kanana-nano-2.1b-instruct (HuggingFace GGUF: ch00n/kanana-nano-2.1b-instruct-Q4_K_M-GGUF)
MODEL_NAME="${OLLAMA_MODEL:-kanana-counseling}"
echo "ğŸ“¦ Checking model: ${MODEL_NAME}..."

if ! ollama list | grep -q "${MODEL_NAME}"; then
    # kanana-counseling (finetuned ëª¨ë¸) - ë¡œì»¬ GGUF íŒŒì¼ ì‚¬ìš©
    if [ "${MODEL_NAME}" = "kanana-counseling" ]; then
        echo "ğŸ“ Registering finetuned model: ${MODEL_NAME}..."
        GGUF_PATH="/app/models/kanana-counseling-q4_k_m.gguf"
        
        if [ -f "${GGUF_PATH}" ]; then
            # Modelfile ìƒì„± ë° ë“±ë¡
            cat > /tmp/Modelfile.${MODEL_NAME} << 'EOF'
FROM /app/models/kanana-counseling-q4_k_m.gguf

SYSTEM """ë‹¹ì‹ ì€ ë…¸ì¸ê±´ê°•ì „ë¬¸ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
- 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ê³µê° í›„ ì§ˆë¬¸ìœ¼ë¡œ ë¬¸ì œë¥¼ íŒŒì•…í•˜ì„¸ìš”
- ì¼ìƒì—ì„œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ê±´ê°• ìŠµê´€ì„ ì•ˆë‚´í•˜ì„¸ìš”
- ì‹¬ê°í•œ ê²½ìš°ì—ë§Œ ë³‘ì› ì§„ë£Œë¥¼ ê¶Œìœ í•˜ì„¸ìš”

[ê¸ˆì§€ì‚¬í•­]
ì ˆëŒ€ë¡œ "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë¶ˆí¸í•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”"ë¼ê³  ë§í•˜ì§€ ë§ˆì„¸ìš”.
ë§ˆë¬´ë¦¬ ì¸ì‚¬ ì—†ì´ í•µì‹¬ ë‚´ìš©ë§Œ ì „ë‹¬í•˜ì„¸ìš”."""

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_predict 256
PARAMETER stop "<|im_end|>"
PARAMETER stop "<|im_start|>"
PARAMETER stop "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ"
PARAMETER stop "ê¶ê¸ˆí•œ ì ì´ë‚˜"
PARAMETER stop "ë¶ˆí¸í•œ ì ì´"
PARAMETER stop "ì–¸ì œë“ ì§€ ë§ì”€"

TEMPLATE """{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
{{ .Response }}<|im_end|>
"""
EOF
            ollama create ${MODEL_NAME} -f /tmp/Modelfile.${MODEL_NAME}
            echo "âœ… ${MODEL_NAME} model registered!"
        else
            echo "âŒ GGUF file not found: ${GGUF_PATH}"
            echo "   Falling back to base kanana model..."
            MODEL_NAME="kanana"
        fi
    fi
    
    # kanana ëª¨ë¸ì€ HuggingFaceì—ì„œ GGUF ë‹¤ìš´ë¡œë“œ í›„ ë“±ë¡
    if [ "${MODEL_NAME}" = "kanana" ]; then
        echo "â¬‡ï¸ Downloading kanana-nano-2.1b-instruct from HuggingFace..."
        echo "   Source: ch00n/kanana-nano-2.1b-instruct-Q4_K_M-GGUF"
        GGUF_URL="https://huggingface.co/ch00n/kanana-nano-2.1b-instruct-Q4_K_M-GGUF/resolve/main/kanana-nano-2.1b-instruct-q4_k_m.gguf"
        GGUF_PATH="/app/models/${MODEL_NAME}.gguf"
        
        # ë‹¤ìš´ë¡œë“œ (ì¬ì‹œë„ í¬í•¨)
        for attempt in 1 2 3; do
            if curl -L --retry 3 --retry-delay 5 -o "${GGUF_PATH}" "${GGUF_URL}"; then
                echo "âœ… GGUF downloaded successfully!"
                break
            else
                echo "âš ï¸ Download attempt $attempt failed, retrying..."
                sleep 5
            fi
            if [ $attempt -eq 3 ]; then
                echo "âŒ Failed to download GGUF after 3 attempts"
                exit 1
            fi
        done
        
        # Modelfile ìƒì„± ë° ë“±ë¡
        cat > /tmp/Modelfile.${MODEL_NAME} << EOF
FROM ${GGUF_PATH}
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_predict 512
SYSTEM "ë‹¹ì‹ ì€ ì¹˜ë§¤ë…¸ì¸ì„ ëŒë³´ëŠ” ë”°ëœ»í•˜ê³  ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
EOF
        echo "ğŸ“ Registering ${MODEL_NAME} model with Ollama..."
        ollama create ${MODEL_NAME} -f /tmp/Modelfile.${MODEL_NAME}
        echo "âœ… ${MODEL_NAME} model registered!"
    elif [ "${MODEL_NAME}" != "kanana-counseling" ]; then
        # ì¼ë°˜ Ollama ëª¨ë¸ pull (kanana, kanana-counselingì´ ì•„ë‹Œ ê²½ìš°)
        echo "â¬‡ï¸ Pulling model: ${MODEL_NAME} (this may take a while on first run)..."
        echo "   Progress logs suppressed. Please wait..."
        # 3ë²ˆ ì¬ì‹œë„ (ì§„í–‰ ìƒí™© ë¡œê·¸ ìˆ¨ê¹€)
        for attempt in 1 2 3; do
            if ollama pull ${MODEL_NAME} 2>&1 | grep -E "(success|error|failed|pulling [a-f0-9]+:.*100%)" || [ ${PIPESTATUS[0]} -eq 0 ]; then
                echo "âœ… Model pulled successfully!"
                break
            else
                echo "âš ï¸ Pull attempt $attempt failed, retrying..."
                sleep 5
            fi
            if [ $attempt -eq 3 ]; then
                echo "âŒ Failed to pull model after 3 attempts"
                exit 1
            fi
        done
    fi
else
    echo "âœ… Model already available!"
fi

# ëª¨ë¸ ê²€ì¦ (í•œê¸€ í…ŒìŠ¤íŠ¸) - ë¡œê·¸ ê°„ì†Œí™”
echo "ğŸ” Verifying model..."
KOREAN_TEST=$(curl -s http://localhost:11434/api/generate -d "{\"model\": \"${MODEL_NAME}\", \"prompt\": \"ì•ˆë…•í•˜ì„¸ìš”ë¼ê³  ë§í•´ì£¼ì„¸ìš”\", \"stream\": false}" 2>&1)
if echo "$KOREAN_TEST" | grep -q "ì•ˆë…•"; then
    echo "âœ… Korean language support verified!"
else
    echo "âš ï¸ Model may have issues with Korean, but continuing..."
fi

# ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (ì›Œë°ì—…) - ë¡œê·¸ ê°„ì†Œí™”
echo "ğŸ”¥ Warming up model..."
curl -s http://localhost:11434/api/generate -d "{\"model\": \"${MODEL_NAME}\", \"prompt\": \"hello\", \"stream\": false}" > /dev/null 2>&1 || true
echo "âœ… Model ready!"

# ChromaDB ìƒíƒœ í™•ì¸ ë° ë¬¸ì„œ ì´ˆê¸°í™”
echo "ğŸ“š Checking ChromaDB data..."
if [ -d "/app/data/chroma" ]; then
    echo "âœ… ChromaDB directory exists"
    ls -la /app/data/chroma/ || true
else
    echo "âš ï¸ ChromaDB directory not found, creating..."
    mkdir -p /app/data/chroma
fi

# ë¬¸ì„œ ìˆ˜ í™•ì¸ ë° ì´ˆê¸°í™” (Pythonìœ¼ë¡œ)
# ìƒˆ ë¬¸ì„œê°€ ì¶”ê°€ëœ ê²½ìš°ì—ë„ ìë™ìœ¼ë¡œ ë¡œë“œ
echo "ğŸ“„ Checking and loading documents..."
python3 -c "
from pathlib import Path
from app.vector_store import get_chroma_handler
chroma = get_chroma_handler()
stats = chroma.get_collection_stats()
print(f'Current - Documents: {stats[\"documents\"]}')
print(f'          Conversations: {stats[\"conversations\"]}')
print(f'          Profiles: {stats[\"patient_profiles\"]}')

# í•­ìƒ healthcare_docs í´ë”ì˜ ë¬¸ì„œë¥¼ í™•ì¸í•˜ê³  ìƒˆ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ë¡œë“œ
import sys
sys.path.insert(0, '/app')
docs_dir = Path('/app/data/healthcare_docs')

if docs_dir.exists():
    # í´ë” ë‚´ ë¬¸ì„œ íŒŒì¼ ìˆ˜ í™•ì¸
    doc_files = list(docs_dir.glob('*.txt')) + list(docs_dir.glob('*.md'))
    print(f'ğŸ“ Found {len(doc_files)} document files in healthcare_docs/')
    
    if len(doc_files) > stats['documents']:
        print('â¬†ï¸ New documents detected, reloading all documents...')
        from scripts.load_healthcare_docs import load_all_documents
        load_all_documents(docs_dir)
        stats = chroma.get_collection_stats()
        print(f'After loading - Documents: {stats[\"documents\"]}')
    elif stats['documents'] == 0:
        print('âš ï¸ No documents in DB, loading healthcare docs...')
        from scripts.load_healthcare_docs import load_all_documents
        load_all_documents(docs_dir)
        stats = chroma.get_collection_stats()
        print(f'After loading - Documents: {stats[\"documents\"]}')
    else:
        print('âœ… Documents already up to date')
else:
    print(f'âš ï¸ Healthcare docs directory not found: {docs_dir}')
"

# FastAPI ì•± ì‹¤í–‰
echo "ğŸŒ Starting FastAPI server on port ${PORT:-8000}..."
exec uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8000}
