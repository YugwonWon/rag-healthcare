#!/bin/bash
# Cloud Runìš© ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸: Ollama + FastAPI (ë²”ìš© ëª¨ë¸ ì§€ì›)
#
# ëª¨ë¸ ë“±ë¡ ë°©ì‹:
#   1. models/{ëª¨ë¸ëª…}.gguf + models/Modelfile.{ëª¨ë¸ëª…} ì´ ìˆìœ¼ë©´ â†’ ìë™ ë“±ë¡
#   2. Modelfileë§Œ ìˆìœ¼ë©´ â†’ Modelfileë¡œ ë“±ë¡ (GGUF ê²½ë¡œê°€ Modelfile ì•ˆì— ì§€ì •)
#   3. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ â†’ ollama pullë¡œ ë‹¤ìš´ë¡œë“œ ì‹œë„

set -e

export PYTHONIOENCODING=utf-8
export OLLAMA_DEBUG=0

# â”€â”€â”€ 1. Ollama ì„œë²„ ì‹œì‘ â”€â”€â”€
echo "ğŸš€ Starting Ollama server..."
ollama serve 2>&1 | grep -v "print_info\|llama_\|ggml_\|rope_\|vocab\|token" &
OLLAMA_PID=$!

echo "â³ Waiting for Ollama to be ready..."
for i in {1..60}; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama is ready!"
        break
    fi
    if [ $i -eq 60 ]; then
        echo "âŒ Ollama failed to start"
        exit 1
    fi
    sleep 1
done

# â”€â”€â”€ 2. ëª¨ë¸ ë“±ë¡ (ë²”ìš©) â”€â”€â”€
MODEL_NAME="${OLLAMA_MODEL:-k-exaone-counseling}"
MODELS_DIR="/app/models"
GGUF_FILE="${MODELS_DIR}/${MODEL_NAME}.gguf"
MODELFILE="${MODELS_DIR}/Modelfile.${MODEL_NAME}"

echo "ğŸ“¦ Model: ${MODEL_NAME}"
echo "   GGUF:      ${GGUF_FILE}"
echo "   Modelfile:  ${MODELFILE}"

if ollama list 2>/dev/null | grep -q "${MODEL_NAME}"; then
    echo "âœ… Model already registered!"
else
    if [ -f "${MODELFILE}" ]; then
        # Modelfileì´ ìˆìœ¼ë©´ ì‚¬ìš©
        echo "ğŸ“ Registering model with Modelfile..."
        ollama create "${MODEL_NAME}" -f "${MODELFILE}"
        echo "âœ… ${MODEL_NAME} registered!"
    elif [ -f "${GGUF_FILE}" ]; then
        # GGUFë§Œ ìˆìœ¼ë©´ ê¸°ë³¸ Modelfile ìë™ ìƒì„±
        echo "ğŸ“ Generating default Modelfile for ${MODEL_NAME}..."
        cat > /tmp/Modelfile.auto << EOF
FROM ${GGUF_FILE}
SYSTEM "ë‹¹ì‹ ì€ ë…¸ì¸ê±´ê°•ì „ë¬¸ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. 3~4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
PARAMETER temperature 0.1
PARAMETER top_p 0.9
PARAMETER num_predict 512
PARAMETER num_ctx 4096
EOF
        ollama create "${MODEL_NAME}" -f /tmp/Modelfile.auto
        rm -f /tmp/Modelfile.auto
        echo "âœ… ${MODEL_NAME} registered (auto-generated Modelfile)!"
    else
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ Ollama Hubì—ì„œ pull
        echo "â¬‡ï¸ No local files found. Pulling from Ollama Hub: ${MODEL_NAME}..."
        for attempt in 1 2 3; do
            if ollama pull "${MODEL_NAME}" 2>&1 | tail -5; then
                echo "âœ… Model pulled successfully!"
                break
            else
                echo "âš ï¸ Pull attempt $attempt failed, retrying..."
                sleep 5
            fi
            if [ $attempt -eq 3 ]; then
                echo "âŒ Failed to pull model after 3 attempts"
                exit 1
            fi
        done
    fi
fi

# â”€â”€â”€ 3. ëª¨ë¸ ê²€ì¦ (í•œê¸€ í…ŒìŠ¤íŠ¸) â”€â”€â”€
echo "ğŸ” Verifying model..."
KOREAN_TEST=$(curl -s http://localhost:11434/api/generate \
    -d "{\"model\": \"${MODEL_NAME}\", \"prompt\": \"ì•ˆë…•í•˜ì„¸ìš”ë¼ê³  ë§í•´ì£¼ì„¸ìš”\", \"stream\": false}" 2>&1)
if echo "$KOREAN_TEST" | grep -q "ì•ˆë…•"; then
    echo "âœ… Korean language support verified!"
else
    echo "âš ï¸ Model may have issues with Korean, but continuing..."
fi

# ì›Œë°ì—…
echo "ğŸ”¥ Warming up model..."
curl -s http://localhost:11434/api/generate \
    -d "{\"model\": \"${MODEL_NAME}\", \"prompt\": \"hello\", \"stream\": false}" > /dev/null 2>&1 || true
echo "âœ… Model ready!"

# â”€â”€â”€ 4. ë°ì´í„° ì´ˆê¸°í™” â”€â”€â”€
echo "ğŸ“š Checking data store..."
if [ -d "/app/data/chroma" ]; then
    echo "âœ… ChromaDB directory exists"
else
    echo "âš ï¸ ChromaDB directory not found, creating..."
    mkdir -p /app/data/chroma
fi

echo "ğŸ“„ Checking and loading documents..."
python3 -c "
from pathlib import Path
from app.vector_store import get_chroma_handler
chroma = get_chroma_handler()
stats = chroma.get_collection_stats()
print(f'Current - Documents: {stats[\"documents\"]}')
print(f'          Conversations: {stats[\"conversations\"]}')
print(f'          Profiles: {stats[\"patient_profiles\"]}')

import sys
sys.path.insert(0, '/app')
docs_dir = Path('/app/data/healthcare_docs')

if docs_dir.exists():
    doc_files = list(docs_dir.glob('*.txt')) + list(docs_dir.glob('*.md'))
    print(f'ğŸ“ Found {len(doc_files)} document files in healthcare_docs/')
    
    if len(doc_files) > stats['documents'] or stats['documents'] == 0:
        print('â¬†ï¸ Loading documents...')
        from scripts.load_healthcare_docs import load_all_documents
        load_all_documents(docs_dir)
        stats = chroma.get_collection_stats()
        print(f'After loading - Documents: {stats[\"documents\"]}')
    else:
        print('âœ… Documents already up to date')
else:
    print(f'âš ï¸ Healthcare docs directory not found: {docs_dir}')
"

# â”€â”€â”€ 5. FastAPI ì„œë²„ ì‹¤í–‰ â”€â”€â”€
echo "ğŸŒ Starting FastAPI server on port ${PORT:-8000}..."
echo "   Model: ${MODEL_NAME}"
exec uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8000}
