#!/bin/bash
# EXAONE GGUF ëª¨ë¸ì„ Ollamaì— ë“±ë¡í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
# ì‚¬ìš©ë²•: ./scripts/setup_exaone.sh [1.2b|2.4b]

set -e

MODEL_SIZE="${1:-1.2b}"
MODELS_DIR="$(pwd)/models"

mkdir -p "$MODELS_DIR"

echo "ðŸ¤– EXAONE ëª¨ë¸ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸"
echo "   ì„ íƒëœ ëª¨ë¸: EXAONE-${MODEL_SIZE^^}"

# HuggingFaceì—ì„œ GGUF ë‹¤ìš´ë¡œë“œ
if [ "$MODEL_SIZE" = "1.2b" ]; then
    MODEL_NAME="exaone1.2b"
    HF_REPO="LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF"
    # Q4_K_M ì–‘ìží™” ë²„ì „ ì‚¬ìš© (CPU ìµœì í™”, ë” ë¹ ë¦„)
    GGUF_FILE="EXAONE-4.0-1.2B-Q4_K_M.gguf"
    DOWNLOAD_URL="https://huggingface.co/${HF_REPO}/resolve/main/${GGUF_FILE}"
elif [ "$MODEL_SIZE" = "2.4b" ]; then
    MODEL_NAME="exaone2.4b"
    HF_REPO="LGAI-EXAONE/EXAONE-Deep-2.4B-GGUF"
    # Q4_K_M ì–‘ìží™” ë²„ì „ ì‚¬ìš© (CPU ìµœì í™”, ë” ë¹ ë¦„)
    GGUF_FILE="EXAONE-Deep-2.4B-Q4_K_M.gguf"
    DOWNLOAD_URL="https://huggingface.co/${HF_REPO}/resolve/main/${GGUF_FILE}"
else
    echo "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ í¬ê¸°: $MODEL_SIZE"
    echo "   ì‚¬ìš©ë²•: ./scripts/setup_exaone.sh [1.2b|2.4b]"
    exit 1
fi

GGUF_PATH="${MODELS_DIR}/${GGUF_FILE}"

# GGUF íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì—†ëŠ” ê²½ìš°)
if [ ! -f "$GGUF_PATH" ]; then
    echo "â¬‡ï¸ GGUF íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘..."
    echo "   URL: $DOWNLOAD_URL"
    
    # huggingface-cli ì‚¬ìš© ì‹œë„, ì—†ìœ¼ë©´ curl ì‚¬ìš©
    if command -v huggingface-cli &> /dev/null; then
        huggingface-cli download "$HF_REPO" "$GGUF_FILE" --local-dir "$MODELS_DIR"
    else
        curl -L -o "$GGUF_PATH" "$DOWNLOAD_URL"
    fi
    
    echo "âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: $GGUF_PATH"
else
    echo "âœ… GGUF íŒŒì¼ ì´ë¯¸ ì¡´ìž¬: $GGUF_PATH"
fi

# Modelfile ìƒì„± (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
MODELFILE_PATH="${MODELS_DIR}/Modelfile.${MODEL_NAME}"

cat > "$MODELFILE_PATH" << EOF
# EXAONE ${MODEL_SIZE^^} ëª¨ë¸ ì„¤ì •
FROM ${GGUF_PATH}

# í•œêµ­ì–´ í—¬ìŠ¤ì¼€ì–´ ì±—ë´‡ìš© íŒŒë¼ë¯¸í„°
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1
PARAMETER num_predict 1024

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´ ê°•ì œ)
SYSTEM """ë‹¹ì‹ ì€ ì¹˜ë§¤ë…¸ì¸ì„ ëŒë³´ëŠ” ë”°ëœ»í•˜ê³  ì¹œì ˆí•œ AI ë„ìš°ë¯¸ìž…ë‹ˆë‹¤.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. í•œìžë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""
EOF

echo "ðŸ“ Modelfile ìƒì„±: $MODELFILE_PATH"
echo "   FROM ê²½ë¡œ: $GGUF_PATH"

# Ollamaì— ëª¨ë¸ ë“±ë¡
echo "ðŸ”§ Ollamaì— ëª¨ë¸ ë“±ë¡ ì¤‘..."
ollama create "$MODEL_NAME" -f "$MODELFILE_PATH"

echo ""
echo "âœ… ì„¤ì • ì™„ë£Œ!"
echo ""
echo "ì‚¬ìš© ë°©ë²•:"
echo "  1. í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ ë³€ê²½:"
echo "     export OLLAMA_MODEL=${MODEL_NAME}"
echo ""
echo "  2. .env íŒŒì¼ì— ì¶”ê°€:"
echo "     OLLAMA_MODEL=${MODEL_NAME}"
echo ""
echo "  3. ì§ì ‘ í…ŒìŠ¤íŠ¸:"
echo "     ollama run ${MODEL_NAME} \"ì•ˆë…•í•˜ì„¸ìš”\""
echo ""
echo "  4. ì„œë²„ ì‹œìž‘:"
echo "     OLLAMA_MODEL=${MODEL_NAME} ./server.sh"
