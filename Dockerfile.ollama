# 치매노인 맞춤형 헬스케어 RAG 챗봇 - Cloud Run 배포용 (Ollama 포함)
# Ollama + Qwen2.5:3b를 컨테이너 내부에서 실행

FROM python:3.12-slim

# 환경변수 설정
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    LOG_LEVEL=INFO \
    LOG_TO_CONSOLE=true \
    LOG_TO_FILE=true \
    OLLAMA_HOST=0.0.0.0:11434 \
    OLLAMA_MODELS=/app/models \
    OLLAMA_BASE_URL=http://localhost:11434

# 작업 디렉토리 설정
WORKDIR /app

# 시스템 의존성 설치 (Ollama 실행에 필요)
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Ollama 설치
RUN curl -fsSL https://ollama.com/install.sh | sh

# Python 의존성 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 애플리케이션 코드 복사
COPY app/ ./app/
COPY data/ ./data/
COPY scripts/start_with_ollama.sh ./start.sh

# 디렉토리 생성
RUN mkdir -p /app/logs /app/models

# 시작 스크립트 실행 권한
RUN chmod +x ./start.sh

# 포트 노출
EXPOSE 8000

# 헬스체크 (앱이 준비되면 /health 응답)
HEALTHCHECK --interval=30s --timeout=30s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:${PORT:-8000}/health || exit 1

# 시작 스크립트 실행 (Ollama 시작 → 모델 로드 → 앱 실행)
CMD ["./start.sh"]
