"""
ìƒë‹´ ëŒ€í™” ì˜ˆì œë¥¼ íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜
ìˆ˜ë©´ ìƒë‹´ ë“± í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ëŒ€í™”ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import json
import re
from pathlib import Path
from typing import Optional


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ëŒ€í™” ìŠ¤íƒ€ì¼ í•™ìŠµìš© - ê°„ê²°í•˜ê²Œ)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë…¸ì¸ê±´ê°•ì „ë¬¸ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
- 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
- ê³µê° í›„ ì§ˆë¬¸ìœ¼ë¡œ ë¬¸ì œë¥¼ íŒŒì•…
- ì¼ìƒì—ì„œ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” ê±´ê°• ìŠµê´€ ì•ˆë‚´
- ì‹¬ê°í•œ ê²½ìš°ì—ë§Œ ë³‘ì› ì§„ë£Œ ê¶Œìœ """


def parse_conversation_file(file_path: str) -> list[dict]:
    """
    í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ëŒ€í™” íŒŒì¼ì„ íŒŒì‹±
    
    ì§€ì› í˜•ì‹:
    - "User: ë©”ì‹œì§€" / "Assistant: ë©”ì‹œì§€"
    - "ê³ ë ¹ì: ë©”ì‹œì§€" / "ìƒë‹´ì‚¬: ë©”ì‹œì§€"
    - "Agent: ë©”ì‹œì§€"
    """
    conversations = []
    current_conv = {"system": None, "turns": []}
    
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # ëŒ€í™” ë¸”ë¡ ë¶„ë¦¬ (ë¹ˆ ì¤„ 2ê°œ ì´ìƒìœ¼ë¡œ êµ¬ë¶„)
    blocks = re.split(r'\n\s*\n', content)
    
    for block in blocks:
        block = block.strip()
        if not block:
            continue
        
        lines = block.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # System í”„ë¡¬í”„íŠ¸ ê°ì§€
            if line.startswith("System") and "í˜ë¥´ì†Œë‚˜" in line:
                # ìƒˆ ëŒ€í™” ì‹œì‘
                if current_conv["turns"]:
                    conversations.append(current_conv)
                current_conv = {"system": SYSTEM_PROMPT, "turns": []}
                continue
            
            # User/ê³ ë ¹ì í„´
            user_match = re.match(r'^(User|ê³ ë ¹ì|ì´ìš©ì)\s*[:\uff1a]\s*(.+)', line)
            if user_match:
                content = user_match.group(2).strip().strip('"')
                if content:
                    current_conv["turns"].append({
                        "role": "user",
                        "content": content
                    })
                continue
            
            # Assistant/ìƒë‹´ì‚¬/Agent í„´
            assistant_match = re.match(r'^(Assistant|Agent|ìƒë‹´ì‚¬)\s*[:\uff1a]\s*(.+)', line)
            if assistant_match:
                content = assistant_match.group(2).strip().strip('"')
                # [ëŒ€ê´„í˜¸ ì•ˆì˜ ì§€ì‹œë¬¸] ì œê±° but ë‚´ìš©ì€ ìœ ì§€
                content = re.sub(r'\[([^\]]+)\]', r'(\1)', content)
                if content:
                    current_conv["turns"].append({
                        "role": "assistant",
                        "content": content
                    })
                continue
    
    # ë§ˆì§€ë§‰ ëŒ€í™” ì¶”ê°€
    if current_conv["turns"]:
        conversations.append(current_conv)
    
    return conversations


def convert_to_chat_format(conversations: list[dict]) -> list[dict]:
    """
    ëŒ€í™”ë¥¼ Kanana/Qwen í•™ìŠµ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    ì¶œë ¥ í˜•ì‹:
    {
        "messages": [
            {"role": "system", "content": "..."},
            {"role": "user", "content": "..."},
            {"role": "assistant", "content": "..."}
        ]
    }
    """
    dataset = []
    
    for conv in conversations:
        messages = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system = conv.get("system", SYSTEM_PROMPT)
        messages.append({"role": "system", "content": system})
        
        # ëŒ€í™” í„´
        turns = conv.get("turns", [])
        
        # user-assistant ìŒë§Œ ì¶”ì¶œ
        i = 0
        while i < len(turns):
            if turns[i]["role"] == "user":
                user_msg = turns[i]["content"]
                
                # ë‹¤ìŒ assistant ì‘ë‹µ ì°¾ê¸°
                if i + 1 < len(turns) and turns[i + 1]["role"] == "assistant":
                    assistant_msg = turns[i + 1]["content"]
                    messages.append({"role": "user", "content": user_msg})
                    messages.append({"role": "assistant", "content": assistant_msg})
                    i += 2
                else:
                    i += 1
            else:
                i += 1
        
        # ìµœì†Œ 1ìŒì˜ ëŒ€í™”ê°€ ìˆì–´ì•¼ í•¨
        if len(messages) >= 3:  # system + user + assistant
            dataset.append({"messages": messages})
    
    return dataset


def split_multi_turn_conversations(dataset: list[dict], max_turns: int = 4) -> list[dict]:
    """
    ê¸´ ëŒ€í™”ë¥¼ ì—¬ëŸ¬ ìƒ˜í”Œë¡œ ë¶„í•  (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
    max_turns: ìµœëŒ€ user-assistant ìŒ ìˆ˜
    """
    expanded = []
    
    for sample in dataset:
        messages = sample["messages"]
        system = messages[0]  # system prompt
        turns = messages[1:]  # user/assistant turns
        
        # 2ê°œì”© (user, assistant) ìŒìœ¼ë¡œ ê·¸ë£¹í™”
        pairs = []
        for i in range(0, len(turns) - 1, 2):
            if turns[i]["role"] == "user" and turns[i + 1]["role"] == "assistant":
                pairs.append((turns[i], turns[i + 1]))
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìƒ˜í”Œ ìƒì„±
        if len(pairs) <= max_turns:
            expanded.append(sample)
        else:
            for start in range(len(pairs) - max_turns + 1):
                window = pairs[start:start + max_turns]
                new_messages = [system]
                for user, assistant in window:
                    new_messages.extend([user, assistant])
                expanded.append({"messages": new_messages})
    
    return expanded


def save_jsonl(data: list[dict], file_path: str):
    """JSONL íŒŒì¼ ì €ì¥"""
    Path(file_path).parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, "w", encoding="utf-8") as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    print(f"âœ… ì €ì¥ë¨: {file_path} ({len(data)}ê°œ ìƒ˜í”Œ)")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ìƒë‹´ ëŒ€í™” ë°ì´í„°ì…‹ ì¤€ë¹„")
    parser.add_argument(
        "--input_dir",
        type=str,
        default="./data/conversations",
        help="ì…ë ¥ ëŒ€í™” íŒŒì¼ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./finetuning/data",
        help="ì¶œë ¥ JSONL ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--max_turns",
        type=int,
        default=3,
        help="ìƒ˜í”Œë‹¹ ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜"
    )
    parser.add_argument(
        "--train_ratio",
        type=float,
        default=0.9,
        help="í•™ìŠµ ë°ì´í„° ë¹„ìœ¨"
    )
    
    args = parser.parse_args()
    
    # ëª¨ë“  ëŒ€í™” íŒŒì¼ ì²˜ë¦¬
    input_path = Path(args.input_dir)
    all_conversations = []
    
    for file in input_path.glob("*.txt"):
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {file.name}")
        convs = parse_conversation_file(str(file))
        all_conversations.extend(convs)
        print(f"   â†’ {len(convs)}ê°œ ëŒ€í™” ì¶”ì¶œ")
    
    if not all_conversations:
        print("âš ï¸ ëŒ€í™” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í˜•ì‹ ë³€í™˜
    dataset = convert_to_chat_format(all_conversations)
    print(f"\nğŸ“Š ë³€í™˜ëœ ìƒ˜í”Œ: {len(dataset)}ê°œ")
    
    # ë©€í‹°í„´ ë¶„í• 
    expanded = split_multi_turn_conversations(dataset, args.max_turns)
    print(f"ğŸ“Š ë¶„í•  í›„ ìƒ˜í”Œ: {len(expanded)}ê°œ")
    
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    import random
    random.seed(42)
    random.shuffle(expanded)
    
    split_idx = int(len(expanded) * args.train_ratio)
    train_data = expanded[:split_idx]
    val_data = expanded[split_idx:]
    
    # ì €ì¥
    output_path = Path(args.output_dir)
    save_jsonl(train_data, output_path / "train_counseling.jsonl")
    save_jsonl(val_data, output_path / "val_counseling.jsonl")
    
    # ìƒ˜í”Œ ì¶œë ¥
    if train_data:
        print("\nğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
        sample = train_data[0]
        for msg in sample["messages"][:5]:
            role = msg["role"]
            content = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
            print(f"  [{role}] {content}")


if __name__ == "__main__":
    main()
