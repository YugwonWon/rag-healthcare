"""
LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤
ê° ë…¸ë“œëŠ” ConversationStateë¥¼ ë°›ì•„ ë³€ê²½í•  í•„ë“œë§Œ dictë¡œ ë°˜í™˜í•œë‹¤.
"""

from app.graph import ConversationState, Intent
from app.graph.intent_classifier import classify_intent
from app.graph.query_rewriter import rewrite_query, extract_topic
from app.config import settings, prompts
from app.model import get_llm
from app.langchain_store import get_langchain_store
from app.preprocessing import HealthSignalDetector
from app.utils import get_kst_now, get_kst_datetime_str
from app.logger import get_logger

logger = get_logger(__name__)

# ì „ì²˜ë¦¬ ëª¨ë“ˆ (ì§€ì—° ì´ˆê¸°í™”)
_health_detector: HealthSignalDetector | None = None


def _get_health_detector() -> HealthSignalDetector:
    global _health_detector
    if _health_detector is None:
        _health_detector = HealthSignalDetector(use_ner_model=True)
    return _health_detector


# ============================================================
# ë…¸ë“œ 1: ì „ì²˜ë¦¬ â€” NER + ê±´ê°• ë¶„ì„ + ëŒ€í™” ì´ë ¥ ë¡œë”©
# ============================================================

async def preprocess_node(state: ConversationState) -> dict:
    """ì „ì²˜ë¦¬: ê±´ê°• ë¶„ì„, ëŒ€í™” ì´ë ¥ ë¡œë”©, ì‹œê°„ ì„¤ì •"""
    nickname = state["nickname"]
    message = state["message"]

    logger.info(f"ğŸ“¥ preprocess | nickname={nickname} | msg={message[:40]}...")

    # í˜„ì¬ ì‹œê°„
    current_time = get_kst_datetime_str()

    # NER + N-gram ê±´ê°• ë¶„ì„
    detector = _get_health_detector()
    try:
        health_analysis = detector.get_risk_summary(message)
    except Exception as e:
        logger.warning(f"ê±´ê°• ë¶„ì„ ì˜¤ë¥˜ (ê¸°ë³¸ê°’): {e}")
        health_analysis = {
            "overall_risk": "low",
            "detected_health_terms": [],
            "risk_categories": [],
            "summary": "",
            "enhanced_query": message,
        }

    # í™˜ì í”„ë¡œí•„ ì¡°íšŒ
    store = get_langchain_store()
    patient_profile = await store.get_profile(nickname)

    # ëŒ€í™” ì´ë ¥ ë¡œë”© (ì‹œê°„ìˆœ, ìµœê·¼ Nê°œ)
    conversation_history = await _load_conversation_history(nickname)

    # ì§ì „ ëŒ€í™”ì—ì„œ ì£¼ì œ ì¶”ì¶œ
    recent_topic = ""
    turn_count = len([h for h in conversation_history if h.get("role") == "user"])
    if conversation_history:
        for entry in reversed(conversation_history):
            if entry.get("role") == "user":
                recent_topic = extract_topic(entry["content"])
                break

    return {
        "current_time": current_time,
        "health_analysis": health_analysis,
        "enhanced_query": health_analysis.get("enhanced_query", message),
        "risk_level": health_analysis.get("overall_risk", "low"),
        "detected_symptoms": health_analysis.get("detected_health_terms", []),
        "patient_profile": patient_profile,
        "conversation_history": conversation_history,
        "recent_topic": recent_topic,
        "turn_count": turn_count,
    }


async def _load_conversation_history(nickname: str) -> list[dict]:
    """ëŒ€í™” ì´ë ¥ì„ ì‹œê°„ìˆœìœ¼ë¡œ ë¡œë”©í•œë‹¤."""
    store = get_langchain_store()
    return store.get_recent_conversations(nickname, limit=5)


# ============================================================
# ë…¸ë“œ 2: ì˜ë„ ë¶„ë¥˜
# ============================================================

def classify_intent_node(state: ConversationState) -> dict:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜"""
    message = state["message"]
    recent_topic = state.get("recent_topic", "")
    turn_count = state.get("turn_count", 0)

    intent, confidence = classify_intent(
        message,
        recent_topic=recent_topic,
        turn_count=turn_count,
    )

    logger.info(f"ğŸ·ï¸ intent={intent.value} | confidence={confidence:.2f} | msg={message[:30]}")

    # ì‘ê¸‰ í‚¤ì›Œë“œ ë³„ë„ ì¶”ì¶œ
    from app.graph.intent_classifier import EMERGENCY_KEYWORDS
    emergency_hits = [kw for kw in EMERGENCY_KEYWORDS if kw in message]

    return {
        "intent": intent,
        "intent_confidence": confidence,
        "emergency_keywords": emergency_hits,
    }


# ============================================================
# ë…¸ë“œ 3: ì¿¼ë¦¬ ì¬ì‘ì„± (FOLLOWUP ì˜ë„ì—ì„œë§Œ ì‹¤í–‰)
# ============================================================

def rewrite_query_node(state: ConversationState) -> dict:
    """í›„ì† ì§ˆë¬¸ì¼ ë•Œ ì´ì „ ë§¥ë½ì„ ë°˜ì˜í•´ ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•œë‹¤."""
    intent = state.get("intent")
    message = state["message"]
    history = state.get("conversation_history", [])
    recent_topic = state.get("recent_topic", "")

    if intent == Intent.FOLLOWUP:
        rewritten = rewrite_query(message, history, recent_topic)
        logger.info(f"âœï¸ ì¿¼ë¦¬ ì¬ì‘ì„±: '{message}' â†’ '{rewritten}'")
        return {"rewritten_query": rewritten}

    return {"rewritten_query": message}


# ============================================================
# ë…¸ë“œ 4: ë¬¸ì„œ ê²€ìƒ‰ (RAG + GraphRAG)
# ============================================================

def retrieve_node(state: ConversationState) -> dict:
    """ë²¡í„° ê²€ìƒ‰ + ì§€ì‹ê·¸ë˜í”„ ê²€ìƒ‰"""
    # ì¬ì‘ì„±ëœ ì¿¼ë¦¬ ë˜ëŠ” í™•ì¥ ì¿¼ë¦¬ ì‚¬ìš©
    query = state.get("rewritten_query") or state.get("enhanced_query") or state["message"]
    intent = state.get("intent", Intent.GENERAL_CHAT)

    # ì¼ë°˜ ëŒ€í™”ë©´ ë¬¸ì„œ ê²€ìƒ‰ ìƒëµ
    if intent == Intent.GENERAL_CHAT:
        return {
            "retrieved_docs": [],
            "graph_context": "",
        }

    # ë²¡í„° ê²€ìƒ‰
    retrieved_docs = []
    store = get_langchain_store()
    doc_results = store.search_documents(query, k=settings.RAG_TOP_K)
    # ëŒ€í™” ì˜ˆì œ(conversations)ëŠ” ì œì™¸í•˜ê³  healthcare_docsë§Œ ì°¸ê³  ì •ë³´ë¡œ ì‚¬ìš©
    retrieved_docs = [
        d.get("content", "")[:300] for d in doc_results
        if d.get("metadata", {}).get("category") != "conversations"
    ]

    # GraphRAG ì§€ì‹ê·¸ë˜í”„ ê²€ìƒ‰
    graph_context = ""
    try:
        from app.knowledge_graph.graph_rag import get_graph_rag
        graph_rag = get_graph_rag()
        graph_context = graph_rag.search(query)
    except Exception as e:
        logger.debug(f"GraphRAG ê²€ìƒ‰ ìŠ¤í‚µ: {e}")

    logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ | docs={len(retrieved_docs)} | graph={'ìˆìŒ' if graph_context else 'ì—†ìŒ'}")

    return {
        "retrieved_docs": retrieved_docs,
        "graph_context": graph_context,
    }


# ============================================================
# ë…¸ë“œ 5-A: ì‘ê¸‰ ìƒí™© ì²˜ë¦¬
# ============================================================

def emergency_node(state: ConversationState) -> dict:
    """ì‘ê¸‰ ìƒí™© ì•Œë¦¼ ìƒì„±"""
    nickname = state["nickname"]
    message = state["message"]
    keywords = state.get("emergency_keywords", [])
    profile = state.get("patient_profile", {})

    emergency_contact = profile.get("emergency_contact", "")

    alert = {
        "level": "critical",
        "message": message,
        "keywords": keywords,
        "nickname": nickname,
        "emergency_contact": emergency_contact,
        "action_required": True,
    }

    logger.warning(f"ğŸš¨ ì‘ê¸‰ ì•Œë¦¼ ìƒì„± | nickname={nickname} | keywords={keywords}")

    return {"emergency_alert": alert}


# ============================================================
# ë…¸ë“œ 6: LLM ì‘ë‹µ ìƒì„±
# ============================================================

async def generate_response_node(state: ConversationState) -> dict:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± + LLM í˜¸ì¶œ"""
    intent = state.get("intent", Intent.GENERAL_CHAT)
    message = state["message"]
    nickname = state["nickname"]

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ
    current_time = state.get("current_time", "")
    patient_info = _format_patient_info(state.get("patient_profile"))
    conversation_history = _format_history(state.get("conversation_history", []))
    retrieved_context = _format_docs(state.get("retrieved_docs", []))
    graph_context = state.get("graph_context", "")

    # ì¼ë°˜ ëŒ€í™”ë©´ ì°¸ê³  ì •ë³´ë¥¼ ë¹„ì›Œì„œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ë„
    if intent == Intent.GENERAL_CHAT:
        retrieved_context = "ì¼ë°˜ ëŒ€í™” - ì°¸ê³  ì •ë³´ ë¶ˆí•„ìš”"
        graph_context = ""

    # ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³  ì •ë³´ì— ì¶”ê°€
    if graph_context:
        retrieved_context = f"{retrieved_context}\n\n[ê±´ê°• ì§€ì‹ê·¸ë˜í”„]\n{graph_context}"

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = prompts.SYSTEM_PROMPT.format(
        current_time=current_time,
        patient_info=patient_info,
        conversation_history=conversation_history,
        retrieved_context=retrieved_context,
    )

    # ì˜ë„ë³„ ì¶”ê°€ ì§€ì‹œ
    if intent == Intent.EMERGENCY:
        system_prompt += (
            "\n\n[âš ï¸ ì‘ê¸‰ ìƒí™© ê°ì§€]\n"
            "ì‚¬ìš©ìì—ê²Œ ì¦‰ì‹œ 119ì— ì „í™”í•˜ê±°ë‚˜ ë³´í˜¸ìì—ê²Œ ì—°ë½í•˜ë„ë¡ ì•ˆë‚´í•˜ì„¸ìš”.\n"
            "ì¹¨ì°©í•˜ê²Œ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , ì•ˆì „í•œ ìì„¸ë¥¼ ìœ ì§€í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤."
        )
    elif intent == Intent.FOLLOWUP:
        rewritten = state.get("rewritten_query", message)
        system_prompt += f"\n\n[ë§¥ë½ ì°¸ê³ ] ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ì´ì „ ëŒ€í™”ì˜ í›„ì†ì…ë‹ˆë‹¤. ì¬ì‘ì„±ëœ ì§ˆë¬¸: {rewritten}"
    elif intent == Intent.MEDICATION:
        system_prompt += "\n\n[ë³µì•½ ê´€ë ¨] ì•½ì— ëŒ€í•œ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì•ˆë‚´í•˜ë˜, ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ë„ë¡ ê¶Œìœ í•˜ì„¸ìš”."

    # ê±´ê°• ìœ„í—˜ ê°ì§€ ì‹œ ì¶”ê°€
    risk_level = state.get("risk_level", "low")
    if risk_level in ("high", "critical"):
        health_analysis = state.get("health_analysis", {})
        terms = health_analysis.get("detected_health_terms", [])
        system_prompt += f"\n\n[ê±´ê°• ìœ„í—˜ ê°ì§€] ìœ„í—˜ ìˆ˜ì¤€: {risk_level}, ê°ì§€ ìš©ì–´: {', '.join(terms[:5])}"
        system_prompt += "\nì£¼ì˜: í•„ìš”ì‹œ ë³´í˜¸ì ì—°ë½ì´ë‚˜ ì „ë¬¸ê°€ ìƒë‹´ì„ ì•ˆë‚´í•˜ì„¸ìš”."

    # LLM í˜¸ì¶œ
    llm = get_llm()
    user_msg = state.get("rewritten_query", message) if intent == Intent.FOLLOWUP else message

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_msg},
    ]

    response = await llm.chat(messages)
    logger.info(f"ğŸ’¬ ì‘ë‹µ ìƒì„± ì™„ë£Œ | intent={intent.value} | len={len(response)}")

    return {
        "response": response,
        "system_prompt": system_prompt,
    }


# ============================================================
# ë…¸ë“œ 7: ëŒ€í™” ì €ì¥
# ============================================================

def save_conversation_node(state: ConversationState) -> dict:
    """ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•œë‹¤."""
    nickname = state["nickname"]
    message = state["message"]
    response = state.get("response", "")
    health_analysis = state.get("health_analysis", {})
    intent = state.get("intent", Intent.GENERAL_CHAT)

    metadata = {
        "intent": intent.value if isinstance(intent, Intent) else str(intent),
        "health_terms": health_analysis.get("detected_health_terms", [])[:5],
        "risk_level": state.get("risk_level", "low"),
        "risk_categories": [
            r["category"] for r in health_analysis.get("risk_categories", [])
        ],
    }

    try:
        store = get_langchain_store()
        store.save_conversation(nickname, message, response)
        logger.debug(f"ğŸ’¾ ëŒ€í™” ì €ì¥ ì™„ë£Œ | nickname={nickname}")
    except Exception as e:
        logger.error(f"ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")

    return {}


# ============================================================
# í—¬í¼ í•¨ìˆ˜
# ============================================================

def _format_patient_info(profile: dict | None) -> str:
    if not profile:
        return "ë“±ë¡ëœ í™˜ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    lines = []
    for k, v in profile.items():
        if k != "nickname" and v:
            lines.append(f"- {k}: {v}")
    return "\n".join(lines) if lines else "ê¸°ë³¸ ì •ë³´ë§Œ ë“±ë¡ë¨"


def _format_history(history: list[dict]) -> str:
    if not history:
        return "ì´ì „ ëŒ€í™” ì—†ìŒ"
    parts = []
    for entry in history[-6:]:  # ìµœê·¼ 3ìŒ
        role = "ì‚¬ìš©ì" if entry.get("role") == "user" else "AI"
        content = entry.get("content", "")[:200]
        parts.append(f"{role}: {content}")
    return "\n".join(parts)


def _format_docs(docs: list[str]) -> str:
    if not docs:
        return "ê´€ë ¨ ì˜ë£Œ ì •ë³´ ì—†ìŒ"
    parts = []
    for i, doc in enumerate(docs[:3], 1):
        parts.append(f"[{i}] {doc}")
    return "\n\n".join(parts)
