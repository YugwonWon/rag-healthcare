"""
GraphRAG ê²€ìƒ‰ê¸° (Neo4j ê¸°ë°˜)
Neo4j ì§€ì‹ê·¸ë˜í”„ + ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

í‚¤ì›Œë“œ ì¶”ì¶œ 3ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ:
  1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ â€” ê·¸ë˜í”„ ë…¸ë“œëª… ì§ì ‘ë§¤ì¹­ + êµ¬ì–´â†’ì˜í•™ìš©ì–´ regex (ì¦‰ì‹œ, 0ms)
  2ë‹¨ê³„: ì„ë² ë”© ìœ ì‚¬ë„ â€” sentence-transformerë¡œ ë…¸ë“œ ì˜ë¯¸ ë§¤ì¹­ (+30ms)
  3ë‹¨ê³„: LLM Fallback â€” 1~2ë‹¨ê³„ ê²°ê³¼ ë¶€ì¡± ì‹œ Ollamaì— ì˜í•™ í‚¤ì›Œë“œ ì¶”ì¶œ ìš”ì²­ (+500ms~2s)
"""

import re
from typing import Optional

import numpy as np

from app.knowledge_graph.health_kg import Neo4jHealthKG, get_neo4j_kg, NodeLabel
from app.config import settings
from app.logger import get_logger
from app.model.local_model import get_embedding_model

logger = get_logger(__name__)

# â”€â”€ ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­ ì„¤ì • â”€â”€
EMBEDDING_SIMILARITY_THRESHOLD = 0.55
EMBEDDING_TOP_K = 2
EMBEDDING_GAP_THRESHOLD = 0.04


class GraphRAGRetriever:
    """Neo4j ì§€ì‹ê·¸ë˜í”„ ê¸°ë°˜ RAG ê²€ìƒ‰ê¸° (í•˜ì´ë¸Œë¦¬ë“œ í‚¤ì›Œë“œ ì¶”ì¶œ)"""

    def __init__(self, kg: Optional[Neo4jHealthKG] = None):
        self.kg = kg or get_neo4j_kg()
        # â”€â”€ ì„ë² ë”© ì¸ë±ìŠ¤ (ì•± ì‹œì‘ ì‹œ 1íšŒ êµ¬ì¶•) â”€â”€
        self._node_names: list[str] = []
        self._node_embeddings: Optional[np.ndarray] = None
        self._embedding = get_embedding_model()
        self._build_node_index()

    def _build_node_index(self):
        """Neo4jì˜ ëª¨ë“  ë…¸ë“œëª…ì„ ì„ë² ë”©í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•œë‹¤."""
        try:
            node_names = self.kg.get_all_node_names()
            if not node_names:
                logger.warning("Neo4jì— ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤. build_neo4j_kg.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                return

            self._node_names = node_names
            self._node_embeddings = self._embedding.embed(node_names)
            logger.info(
                f"ğŸ”— GraphRAG ë…¸ë“œ ì„ë² ë”© ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: "
                f"{len(self._node_names)}ê°œ ë…¸ë“œ, "
                f"model={settings.EMBEDDING_MODEL}, "
                f"dim={self._node_embeddings.shape[1]}"
            )
        except Exception as e:
            logger.warning(f"ë…¸ë“œ ì„ë² ë”© ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨ (ê·œì¹™ ê¸°ë°˜+LLMë§Œ ì‚¬ìš©): {e}")
            self._node_embeddings = None

    def rebuild_index(self):
        """ë…¸ë“œ ì„ë² ë”© ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•œë‹¤ (ê·¸ë˜í”„ ë³€ê²½ í›„ í˜¸ì¶œ)."""
        self._node_names = []
        self._node_embeddings = None
        self._build_node_index()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ê²€ìƒ‰ ë©”ì¸ ì—”íŠ¸ë¦¬
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def search(self, query: str) -> str:
        """
        ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  Neo4j ì§€ì‹ê·¸ë˜í”„ë¥¼ íƒìƒ‰í•˜ì—¬
        êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ë°˜í™˜í•œë‹¤.
        """
        keywords = self._extract_keywords_hybrid(query)

        if not keywords:
            return ""

        context_parts = []

        for keyword in keywords:
            # 1. ì¦ìƒâ†’ì§ˆí™˜ ê²½ë¡œ íƒìƒ‰
            conditions = self.kg.get_symptom_conditions(keyword)
            for cond in conditions:
                info = self.kg.get_condition_info(cond)
                if info:
                    context_parts.append(self._format_condition_info(info))

            # 2. ì§ˆí™˜ ì§ì ‘ ë§¤ì¹­
            info = self.kg.get_condition_info(keyword)
            if info and info.get("symptoms"):
                context_parts.append(self._format_condition_info(info))

            # 3. ê´€ë ¨ ë…¸ë“œ íƒìƒ‰ (ê¹Šì´ 2)
            if not conditions and not (info and info.get("symptoms")):
                related = self.kg.find_related_nodes(keyword, depth=2)
                if related:
                    summary = self._format_related_nodes(keyword, related)
                    if summary:
                        context_parts.append(summary)

        # ì¤‘ë³µ ì œê±°
        unique_parts = list(dict.fromkeys(context_parts))
        result = "\n".join(unique_parts[:3])  # ìµœëŒ€ 3ê°œ ì§ˆí™˜ ì •ë³´

        if result:
            logger.info(f"ğŸ§  GraphRAG | keywords={keywords} | context_len={len(result)}")

        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # í•˜ì´ë¸Œë¦¬ë“œ í‚¤ì›Œë“œ ì¶”ì¶œ (3ë‹¨ê³„)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _extract_keywords_hybrid(self, query: str) -> list[str]:
        """
        3ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ í‚¤ì›Œë“œ ì¶”ì¶œ:
        1) ê·œì¹™ ê¸°ë°˜ (ì§ì ‘ë§¤ì¹­ + regex)  â€” ~0ms
        2) ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­            â€” ~30ms
        3) LLM Fallback                 â€” ~500ms~2s (í•„ìš”ì‹œë§Œ)
        """
        keywords = []

        # â”€â”€ Stage 1: ê·œì¹™ ê¸°ë°˜ â”€â”€
        rule_keywords = self._extract_by_rules(query)
        keywords.extend(rule_keywords)

        # â”€â”€ Stage 2: ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­ â”€â”€
        embed_keywords = self._extract_by_embedding(query)
        for kw in embed_keywords:
            if kw not in keywords:
                keywords.append(kw)

        # â”€â”€ Stage 3: LLM Fallback (1~2ë‹¨ê³„ ê²°ê³¼ê°€ ë¶€ì¡±í•  ë•Œë§Œ) â”€â”€
        if len(keywords) == 0:
            llm_keywords = self._extract_by_llm(query)
            for kw in llm_keywords:
                if kw not in keywords:
                    keywords.append(kw)

        if keywords:
            logger.info(
                f"ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ | "
                f"rule={rule_keywords} | "
                f"embed={embed_keywords} | "
                f"final={keywords[:5]}"
            )

        return keywords[:5]

    # â”€â”€ Stage 1: ê·œì¹™ ê¸°ë°˜ â”€â”€

    def _extract_by_rules(self, query: str) -> list[str]:
        """ê·¸ë˜í”„ ë…¸ë“œëª… ì§ì ‘ë§¤ì¹­ + êµ¬ì–´â†’ì˜í•™ìš©ì–´ regex íŒ¨í„´."""
        keywords = []

        # Neo4jì—ì„œ ë…¸ë“œëª… ê°€ì ¸ì™€ì„œ ì§ì ‘ ë§¤ì¹­
        for name in self._node_names:
            if name in query:
                keywords.append(name)

        # êµ¬ì–´ â†’ ì˜í•™ìš©ì–´ ë§¤í•‘
        colloquial_map = {
            r"ì ì„?\s*ëª»": "ë¶ˆë©´ì¦",
            r"ì ì´?\s*ì•ˆ": "ë¶ˆë©´ì¦",
            r"ë°¤ì—?\s*ê¹¨": "ìˆ˜ë©´ íŒ¨í„´ ë³€í™”",
            r"ë°œí†±.*(ì•ˆ|ì•ˆìª½|íŒŒê³ |ë“¤ì–´)": "ë‚´í–¥ì„± ë°œí†±",
            r"ë°œí†±.*(ë‘êº¼|ë³€í˜•|íœ˜)": "ë°œí†± ë³€í˜•",
            r"ì†Œë³€.*(ëª» ì°¸|ì‹¤ìˆ˜|ìì£¼)": "ìš”ì‹¤ê¸ˆ",
            r"ë¨¸ë¦¬.*(ë¹ ì§€|ë¹ ì ¸|íƒˆëª¨)": "ë¨¸ë¦¬ì¹´ë½ ë¹ ì§",
            r"í”¼ë¶€.*(ê°€ë ¤|ê±´ì¡°|íŠ¸ëŸ¬ë¸”)": "í”¼ë¶€ ê°€ë ¤ì›€",
            r"ìˆ¨.*(ì°¨|ì•ˆ ì‰¬|ëª» ì‰¬)": "í˜¸í¡ê³¤ë€",
            r"ê¸°ì¹¨.*(ì˜¤ë˜|ì•ˆ ë©ˆ|ê³„ì†)": "ë§Œì„±ê¸°ì¹¨",
            r"ì†.*(ì €ë¦¬|ê°ê°)": "ì†ë°œ ì €ë¦¼",
            r"ë°œ.*(ì €ë¦¬|ê°ê°)": "ì†ë°œ ì €ë¦¼",
            r"ê·€.*(ì•ˆ ë“¤|ì˜ ì•ˆ)": "ì†Œë¦¬ ì•ˆ ë“¤ë¦¼",
            r"ëˆˆ.*(ì¹¨ì¹¨|íë¦¿|ì•ˆ ë³´)": "ì‹œë ¥ ì €í•˜",
            r"ì‡ëª¸.*(í”¼|ì¶œí˜ˆ|ë¶“)": "ì‡ëª¸ ì¶œí˜ˆ",
            r"ë³€.*(ì•ˆ ë‚˜|ëª» ë³´|í˜ë“¤)": "ë°°ë³€ ê³¤ë€",
            r"ë°°.*(ë”ë¶€ë£©|íŒ½ë§Œ|ë¶€ë¥¸)": "ë³µë¶€ íŒ½ë§Œ",
            r"ê¸°ìš´.*(ì—†|ë¹ ì§€|ì €í•˜)": "ê¸°ë ¥ ì €í•˜",
            r"ë¼ˆ.*(ì•„í”„|í†µì¦|ì‘¤ì‹œ)": "ë¼ˆ í†µì¦",
            r"í˜ˆë‹¹.*(ë†’|ì˜¬ë¼)": "ê³ í˜ˆë‹¹",
            r"í˜ˆë‹¹.*(ë‚®|ë–¨ì–´)": "ì €í˜ˆë‹¹",
        }

        for pattern, medical_term in colloquial_map.items():
            if re.search(pattern, query):
                if medical_term not in keywords:
                    keywords.append(medical_term)

        return keywords

    # â”€â”€ Stage 2: ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­ â”€â”€

    def _extract_by_embedding(self, query: str) -> list[str]:
        """
        ì¿¼ë¦¬ ì„ë² ë”©ê³¼ ê·¸ë˜í”„ ë…¸ë“œ ì„ë² ë”© ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê´€ë ¨ ë…¸ë“œë¥¼ ì°¾ëŠ”ë‹¤.
        """
        if self._node_embeddings is None or len(self._node_names) == 0:
            return []

        try:
            query_emb = self._embedding.embed([query])  # shape: (1, dim)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            query_norm = query_emb / (np.linalg.norm(query_emb, axis=1, keepdims=True) + 1e-10)
            node_norms = self._node_embeddings / (
                np.linalg.norm(self._node_embeddings, axis=1, keepdims=True) + 1e-10
            )
            similarities = (query_norm @ node_norms.T).flatten()

            sorted_indices = np.argsort(similarities)[::-1]
            top_indices = sorted_indices[:EMBEDDING_TOP_K]

            # ìƒëŒ€ ê°­ ì²´í¬
            if len(sorted_indices) > 3:
                gap = float(similarities[sorted_indices[0]] - similarities[sorted_indices[3]])
                if gap < EMBEDDING_GAP_THRESHOLD:
                    logger.debug(
                        f"ì„ë² ë”© ê°­ ë¶€ì¡±: top1={similarities[sorted_indices[0]]:.3f}, "
                        f"top4={similarities[sorted_indices[3]]:.3f}, gap={gap:.3f}"
                    )
                    return []

            matched = []
            for idx in top_indices:
                score = similarities[idx]
                if score >= EMBEDDING_SIMILARITY_THRESHOLD:
                    node_name = self._node_names[idx]
                    matched.append((node_name, float(score)))

            if matched:
                match_str = ", ".join(
                    f"{name}({score:.2f})" for name, score in matched
                )
                logger.debug(f"ğŸ” ì„ë² ë”© ë§¤ì¹­: query='{query}' â†’ {match_str}")

            return [name for name, _ in matched]

        except Exception as e:
            logger.debug(f"ì„ë² ë”© ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return []

    # â”€â”€ Stage 3: LLM Fallback â”€â”€

    def _extract_by_llm(self, query: str) -> list[str]:
        """
        ê·œì¹™+ì„ë² ë”©ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ëª» ì°¾ì•˜ì„ ë•Œ LLMì—ê²Œ ì˜í•™ í‚¤ì›Œë“œ ì¶”ì¶œì„ ìš”ì²­í•œë‹¤.
        """
        try:
            import httpx

            node_list = ", ".join(self._node_names[:50])

            prompt = (
                "ë‹¹ì‹ ì€ ì˜ë£Œ í‚¤ì›Œë“œ ì¶”ì¶œê¸°ì…ë‹ˆë‹¤.\n"
                "ì•„ë˜ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê±´ê°•/ì˜ë£Œ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                "ë°˜ë“œì‹œ ì•„ë˜ í›„ë³´ ëª©ë¡ì— ìˆëŠ” ë‹¨ì–´ë§Œ ì„ íƒí•˜ì„¸ìš”.\n"
                "í•´ë‹¹ ì—†ìœ¼ë©´ 'ì—†ìŒ'ì´ë¼ê³ ë§Œ ë‹µí•˜ì„¸ìš”.\n\n"
                f"[í›„ë³´ ëª©ë¡]\n{node_list}\n\n"
                f"[ì‚¬ìš©ì ë©”ì‹œì§€]\n{query}\n\n"
                "[ì¶”ì¶œëœ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)]"
            )

            response = httpx.post(
                f"{settings.OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": settings.OLLAMA_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.0,
                        "num_predict": 50,
                    },
                },
                timeout=5.0,
            )
            response.raise_for_status()

            result = response.json().get("response", "").strip()

            if "ì—†ìŒ" in result or not result:
                return []

            # <think>...</think> ë¸”ë¡ ì œê±°
            result = re.sub(r"<think>.*?</think>", "", result, flags=re.DOTALL)
            result = re.sub(r"</?think>", "", result).strip()

            # ì‰¼í‘œë¡œ ë¶„ë¦¬ í›„ ì‹¤ì œ ê·¸ë˜í”„ ë…¸ë“œì¸ì§€ ê²€ì¦
            candidates = [kw.strip() for kw in result.split(",")]
            node_name_set = set(self._node_names)
            valid_keywords = [kw for kw in candidates if kw in node_name_set]

            if valid_keywords:
                logger.info(f"ğŸ¤– LLM í‚¤ì›Œë“œ ì¶”ì¶œ: '{query}' â†’ {valid_keywords}")

            return valid_keywords[:3]

        except Exception as e:
            logger.debug(f"LLM í‚¤ì›Œë“œ ì¶”ì¶œ ìŠ¤í‚µ: {e}")
            return []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # í¬ë§¤íŒ…
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _format_condition_info(self, info: dict) -> str:
        """ì§ˆí™˜ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤."""
        parts = [f"â–¶ {info['condition']}: {info.get('description', '')}"]

        symptoms = info.get("symptoms", [])
        if symptoms:
            symptom_names = [s["name"] for s in symptoms]
            parts.append(f"  ì¦ìƒ: {', '.join(symptom_names)}")

        treatments = info.get("treatments", [])
        if treatments:
            for t in treatments:
                parts.append(f"  ê´€ë¦¬: {t['name']} â€” {t.get('desc', '')}")

        prevention = info.get("prevention", [])
        if prevention:
            prev_names = [p["name"] for p in prevention]
            parts.append(f"  ì˜ˆë°©: {', '.join(prev_names)}")

        risk_factors = info.get("risk_factors", [])
        if risk_factors:
            risk_names = [r["name"] for r in risk_factors]
            parts.append(f"  ìœ„í—˜ìš”ì¸: {', '.join(risk_names)}")

        return "\n".join(parts)

    def _format_related_nodes(self, keyword: str, nodes: list[dict]) -> str:
        """ê´€ë ¨ ë…¸ë“œ ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤."""
        if not nodes:
            return ""

        # íƒ€ì…ë³„ ê·¸ë£¹í•‘
        by_type = {}
        for node in nodes:
            ntype = node.get("type", "unknown")
            if ntype not in by_type:
                by_type[ntype] = []
            by_type[ntype].append(node)

        parts = [f"â–¶ '{keyword}' ê´€ë ¨ ì •ë³´:"]

        type_labels = {
            NodeLabel.CONDITION: "ê´€ë ¨ ì§ˆí™˜",
            NodeLabel.SYMPTOM: "ê´€ë ¨ ì¦ìƒ",
            NodeLabel.TREATMENT: "ê´€ë¦¬ ë°©ë²•",
            NodeLabel.LIFESTYLE: "ìƒí™œ ìŠµê´€",
            NodeLabel.RISK_FACTOR: "ì£¼ì˜ ì‚¬í•­",
        }

        for ntype, label in type_labels.items():
            group = by_type.get(ntype, [])
            if group:
                names = [f"{n['name']}({n.get('desc', '')})" for n in group[:3]]
                parts.append(f"  {label}: {', '.join(names)}")

        return "\n".join(parts) if len(parts) > 1 else ""


# â”€â”€ ì‹±ê¸€í†¤ â”€â”€
_graph_rag: Optional[GraphRAGRetriever] = None


def get_graph_rag() -> GraphRAGRetriever:
    global _graph_rag
    if _graph_rag is None:
        _graph_rag = GraphRAGRetriever()
    return _graph_rag
