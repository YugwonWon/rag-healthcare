# Cloud Run ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

### 1. GCP í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# GCP CLI ì„¤ì¹˜ ë° ë¡œê·¸ì¸
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# í•„ìš”í•œ API í™œì„±í™”
gcloud services enable run.googleapis.com
gcloud services enable containerregistry.googleapis.com
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
export GCP_PROJECT_ID=your-project-id
export GCP_REGION=asia-northeast3
export SERVICE_NAME=healthcare-rag-chatbot
```

## ğŸš€ ë°°í¬ ë°©ë²•

### ë°©ë²• 1: ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x deploy_cloudrun.sh

# ë°°í¬ ì‹¤í–‰
./deploy_cloudrun.sh
```

### ë°©ë²• 2: ìˆ˜ë™ ë°°í¬

```bash
# 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t gcr.io/${GCP_PROJECT_ID}/${SERVICE_NAME}:latest .

# 2. GCRì— í‘¸ì‹œ
docker push gcr.io/${GCP_PROJECT_ID}/${SERVICE_NAME}:latest

# 3. Cloud Run ë°°í¬
gcloud run deploy ${SERVICE_NAME} \
    --image gcr.io/${GCP_PROJECT_ID}/${SERVICE_NAME}:latest \
    --platform managed \
    --region ${GCP_REGION} \
    --allow-unauthenticated \
    --memory 2Gi \
    --cpu 2 \
    --set-env-vars "CHROMA_IN_MEMORY=true"
```

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

Cloud Runì—ì„œ í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜:

| ë³€ìˆ˜ëª… | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|
| `CHROMA_IN_MEMORY` | ì¸ë©”ëª¨ë¦¬ ëª¨ë“œ ì‚¬ìš© | `true` |
| `OLLAMA_BASE_URL` | Ollama ì„œë²„ URL | `http://ollama-server:11434` |
| `OPENAI_API_KEY` | OpenAI API í‚¤ (Fallback) | `sk-...` |

```bash
gcloud run services update ${SERVICE_NAME} \
    --set-env-vars "OPENAI_API_KEY=sk-your-key"
```

## ğŸ”§ Ollama ì„œë²„ ì—°ë™

Cloud Runì—ì„œ Ollamaë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:

### ì˜µì…˜ 1: Compute Engineì— Ollama ì„œë²„ ë°°í¬

```bash
# GPU ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
gcloud compute instances create ollama-server \
    --zone=asia-northeast3-a \
    --machine-type=n1-standard-4 \
    --accelerator=type=nvidia-tesla-t4,count=1 \
    --boot-disk-size=100GB \
    --image-family=ubuntu-2204-lts \
    --image-project=ubuntu-os-cloud

# Ollama ì„¤ì¹˜ (ì¸ìŠ¤í„´ìŠ¤ ë‚´ì—ì„œ)
curl -fsSL https://ollama.com/install.sh | sh
ollama serve &
ollama pull qwen2.5:3b
```

### ì˜µì…˜ 2: OpenAI Fallback ì‚¬ìš©

Ollama ì—†ì´ OpenAI APIë§Œ ì‚¬ìš©:

```bash
gcloud run services update ${SERVICE_NAME} \
    --set-env-vars "OPENAI_API_KEY=sk-your-key"
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸

```bash
gcloud run services logs read ${SERVICE_NAME} --region ${GCP_REGION}
```

### í—¬ìŠ¤ ì²´í¬

```bash
curl https://your-service-url.run.app/health
```

## ğŸ”’ ë³´ì•ˆ ì„¤ì •

### ì¸ì¦ í™œì„±í™”

```bash
gcloud run services update ${SERVICE_NAME} --no-allow-unauthenticated
```

### IAM ì„¤ì •

```bash
# íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
gcloud run services add-iam-policy-binding ${SERVICE_NAME} \
    --member="user:email@example.com" \
    --role="roles/run.invoker"
```

## ğŸ’¡ ë¹„ìš© ìµœì í™”

- `--min-instances 0`: ìœ íœ´ ì‹œ ì¸ìŠ¤í„´ìŠ¤ 0ê°œë¡œ ì¶•ì†Œ
- `--max-instances 10`: ìµœëŒ€ ì¸ìŠ¤í„´ìŠ¤ ì œí•œ
- `--memory 2Gi`: ë©”ëª¨ë¦¬ ìµœì í™” (ì„ë² ë”© ëª¨ë¸ í¬ê¸° ê³ ë ¤)

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì½œë“œ ìŠ¤íƒ€íŠ¸ ëŠë¦¼

ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹œê°„ì´ ê¸¸ ê²½ìš°:

```bash
gcloud run services update ${SERVICE_NAME} --min-instances 1
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
gcloud run services update ${SERVICE_NAME} --memory 4Gi
```

### íƒ€ì„ì•„ì›ƒ ì—ëŸ¬

```bash
gcloud run services update ${SERVICE_NAME} --timeout 300
```
